# Benchmark globals default vaules, can be overwritten later

# Make sure we already have the default user and home path before continuing
[ ! "$userAloja" ] || [ ! "$homePrefixAloja" ] && die "userAloja or homePrefixAloja not set"

# Default benchmark to exectute and options
[ ! "$EXEC_TYPE" ] && EXEC_TYPE="default"
[ ! "$BENCH_SUITE" ] && BENCH_SUITE="Hadoop-Examples" #"HiBench2"
[ ! "$SAVE_BENCH" ] && SAVE_BENCH=""

# Path and folders
[ ! "$BENCH_SHARE_DIR" ] && BENCH_SHARE_DIR="$homePrefixAloja/$userAloja/share" #source dir usually shared over the net
[ ! "$BENCH_LOCAL_DIR" ] && BENCH_LOCAL_DIR="/scratch/local" #local temp dir for writting
[ ! "$BENCH_FOLDER" ] && BENCH_FOLDER="aloja-bench" #name for the main folder
[ ! "$BENCH_SOURCE_DIR" ] && BENCH_SOURCE_DIR="$BENCH_LOCAL_DIR/aplic" #where to get the binaries
[ ! "$BENCH_SAVE_PREPARE_LOCATION" ] && BENCH_SAVE_PREPARE_LOCATION="$BENCH_LOCAL_DIR/aloja-bench_prepare" #where to save prepare bench output
#[ ! "$BENCH_SAVE_PREPARE_LOCATION" ] && BENCH_SAVE_PREPARE_LOCATION="$$BENCH_LOCAL_DIR/aloja-bench_prepare" #where to save prepare bench output

# Logs
ALOJA_FORCE_COLORS="1" #Force colors on screen even when writing log files

# Data sizes and default scale factor
[ ! "$ALOJA_DATA_SIZE" ] && ALOJA_DATA_SIZE="100000000" #100MB, in bytes
ALOJA_SCALE_FACTOR="$(( ALOJA_DATA_SIZE / 1000000 ))" #in MB

# Set to 1 to auto import runs after exectuion e.g. for the vagrant VM
[ ! "$ALOJA_AUTO_IMPORT" ] && ALOJA_AUTO_IMPORT=""

# Default perf monitors and metrics collectors
[ ! "$BENCH_PERF_MONITORS" ] && BENCH_PERF_MONITORS="sar vmstat"
[ ! "$BENCH_PERF_INTERVAL" ] && BENCH_PERF_INTERVAL="1" #1sec.

# HW conf
[ ! "$NET" ] && NET="ETH"
[ ! "$IFACE" ] && IFACE="eth0"
[ ! "$DISK" ] && DISK="HDD"
[ ! "$PORT_PREFIX" ] && PORT_PREFIX="3" #port prefix to allow multiple copies

# SW conf

# Java
[ ! "$BENCH_JAVA_HOME" ] && BENCH_JAVA_HOME="jdk1.7.0_25"
[ ! "$BENCH_JAVA_VERSION" ] && BENCH_JAVA_VERSION="jdk1.7.0_25"
[ ! "$JAVA_XMS" ] && JAVA_XMS="-Xms512m" #START
[ ! "$JAVA_XMX" ] && JAVA_XMX="-Xmx1024m" #MAX
[ ! "$JAVA_AM_XMS" ] && JAVA_AM_XMS="-Xms512m" #START
[ ! "$JAVA_AM_XMX" ] && JAVA_AM_XMX="-Xmx1024m" #MAX

# Hadoop 1 (and some for 2)
[ ! "$HADOOP_VERSION" ] && HADOOP_VERSION="hadoop-1.2.1" #default Hadoop version

# Set the max number of maps (and reducers) to 1 per core by default
if [ ! "$MAX_MAPS" ] ; then
  if [ "$vmCores" ] ; then
    MAX_MAPS="$vmCores"
  else
    die "Numbes of cores not defined for cluster, cannot set maps automatically"
  fi
fi

[ ! "$REPLICATION" ] && REPLICATION=1
[ ! "$BLOCK_SIZE" ] && BLOCK_SIZE=67108864 #64MB in bytes
[ ! "$IO_FACTOR" ] && IO_FACTOR=10
[ ! "$IO_FILE" ] && IO_FILE=65536
[ ! "$COMPRESS_GLOBAL" ] && COMPRESS_GLOBAL=0
[ ! "$COMPRESS_TYPE" ] && COMPRESS_TYPE=0

#COMPRESS_GLOBAL=1
#COMPRESS_TYPE=1
#COMPRESS_CODEC_GLOBAL=org.apache.hadoop.io.compress.DefaultCodec
#COMPRESS_CODEC_GLOBAL=com.hadoop.compression.lzo.LzoCodec
#COMPRESS_CODEC_GLOBAL=org.apache.hadoop.io.compress.SnappyCodec

[ ! "$INSTRUMENTATION" ] && INSTRUMENTATION=0 #if to use extrae
[ ! "$DELETE_HDFS" ] && DELETE_HDFS="1" #if to delete current HDFS files (default)

#Name of tarball with extra jars for HADOOP_USER_CLASSPATH_FIRST from the public repo
[ ! "$HADOOP_EXTRA_JARS" ] && HADOOP_EXTRA_JARS=""

# Hadoop 2
[ ! "$PHYS_MEM" ] && PHYS_MEM=$(echo "scale=4;($vmRAM*1024)-3072" | bc)
[ ! "$NUM_CORES" ] && NUM_CORES="$vmCores"
[ ! "$CONTAINER_MIN_MB" ] && CONTAINER_MIN_MB=768
[ ! "$CONTAINER_MAX_MB" ] && CONTAINER_MAX_MB=4096
[ ! "$MAPS_MB" ] && MAPS_MB=768
[ ! "$REDUCES_MB" ]  && REDUCES_MB=1536
[ ! "$AM_MB" ]  && AM_MB=1536

# Default cluster capabilities
[ ! "$CLUSTER_DISKS" ] &&   CLUSTER_DISKS="HDD" #separate list with spaces
[ ! "$CLUSTER_NETS" ] &&    CLUSTER_NETS="ETH" #separate list with spaces
[ ! "$BENCH_MAX_DISKS" ] && BENCH_MAX_DISKS="8"

# Populate if needed with config folders to rsync
BENCH_CONFIG_FOLDERS=""

# SATA drives (HDDs)
BENCH_DISKS["HDD"]="$BENCH_LOCAL_DIR"

# Create automatically disk paths
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["HD$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# SSDs
BENCH_DISKS["SSD"]="/scratch/ssd/1"

for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["SS$disk_number_tmp"]="/scratch/ssd/$disk_number_tmp"
done

# Remotes
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RR$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Remotes with temp in local
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RL$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Sata with tmp in SSD
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["HS$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Remotes with tmp in SSD
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RS$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done