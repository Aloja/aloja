# Benchmark globals default vaules, can be overwritten later

# Make sure we already have the default user and home path before continuing
[ ! "$userAloja" ] || [ ! "$homePrefixAloja" ] && die "userAloja or homePrefixAloja not set"

# Default benchmark to exectute and options
[ ! "$EXEC_TYPE" ] && EXEC_TYPE="default"
[ ! "$BENCH_SUITE" ] && BENCH_SUITE="Hadoop-Examples" #"HiBench2"
[ ! "$SAVE_BENCH" ] && SAVE_BENCH=""

# Path and folders
[ ! "$BENCH_SHARE_DIR" ] && BENCH_SHARE_DIR="$homePrefixAloja/$userAloja/share" #source dir usually shared over the net
[ ! "$BENCH_LOCAL_DIR" ] && BENCH_LOCAL_DIR="/scratch/local" #local temp dir for writing
[ ! "$BENCH_EXTRA_LOCAL_DIR" ] && BENCH_EXTRA_LOCAL_DIR="/scratch/local" #local temp dir for extra machines
[ ! "$BENCH_FOLDER" ] && BENCH_FOLDER="aloja-bench" #name for the main folder
[ ! "$BENCH_SOURCE_DIR" ] && BENCH_SOURCE_DIR="$BENCH_LOCAL_DIR/aplic" #where to get the binaries
[ ! "$BENCH_SAVE_PREPARE_LOCATION" ] && BENCH_SAVE_PREPARE_LOCATION="$BENCH_LOCAL_DIR/aloja-bench_prepare" #where to save prepare bench output
#[ ! "$BENCH_SAVE_PREPARE_LOCATION" ] && BENCH_SAVE_PREPARE_LOCATION="$$BENCH_LOCAL_DIR/aloja-bench_prepare" #where to save prepare bench output

# Logs
ALOJA_FORCE_COLORS="1" #Force colors on screen even when writing log files

# Data sizes and default scale factor
if [ "$BENCH_SCALE_FACTOR" ] ; then
   BENCH_DATA_SIZE="$(( BENCH_SCALE_FACTOR * 1000000000 ))" #in GB
else
   if [ ! "$BENCH_DATA_SIZE" ] ; then
     # Check if TPC scale factor has been specified
     if [ "$TPCH_SCALE_FACTOR" ] ; then
       BENCH_DATA_SIZE="$(( TPCH_SCALE_FACTOR *  1000000000 ))" # if set, it is in GBs
     else
       BENCH_DATA_SIZE="100000000" #100MB, in bytes #1000000000000 1TB
     fi
   fi
fi

BENCH_SCALE_FACTOR="$(( BENCH_DATA_SIZE / 1000000000 ))" #in GB

# Enable to run multiple times a benchmark, it is useful to repeat a benchmark after a prepare
[ ! "$BENCH_NUM_RUNS" ] && BENCH_NUM_RUNS=""
[ ! "$BENCH_CONCURRENCY" ] && BENCH_CONCURRENCY="0"

# Set to 1 to auto import runs after exectuion e.g. for the vagrant VM
[ ! "$ALOJA_AUTO_IMPORT" ] && ALOJA_AUTO_IMPORT=""

# Default perf monitors and metrics collectors
[ ! "$BENCH_PERF_MONITORS" ] && BENCH_PERF_MONITORS="sar vmstat iostat" # Others: cachestat iotop dstat perf JavaStat drop_cache
[ ! "$BENCH_PERF_INTERVAL" ] && BENCH_PERF_INTERVAL="1" #1sec.
[ ! "$BENCH_PERF_NON_BINARY" ] && BENCH_PERF_NON_BINARY="MapRed" #list of script style perf mons ie. MapRed

# Fast mode, for development testing (repetitive tasks) avoid time consuming tasks
[ ! "$ALOJA_FAST_MODE" ] && ALOJA_FAST_MODE="" || {
  # Fast mode selected
  BENCH_PERF_MONITORS=
  BENCH_PERF_NON_BINARY=
  ALOJA_AUTO_IMPORT=
}

# HW conf
[ ! "$NET" ]          && NET="ETH"
[ ! "$IFACE" ]        && IFACE="eth0"
[ ! "$DISK" ]         && DISK="HDD"
[ ! "$PORT_PREFIX" ]  && PORT_PREFIX="3" #port prefix to allow multiple copies of daemons

# SW conf

# extra parameters passed to the benchmark ie., for Hadoop -D params, for sleep the num of seconds
[ ! "$BENCH_EXTRA_CONFIG" ] && BENCH_EXTRA_CONFIG=""

# Java
[ ! "$BENCH_JAVA_VERSION" ] && BENCH_JAVA_VERSION="jdk1.8.0_101" #"jdk1.7.0_80" #jdk1.7.0_25
[ ! "$JAVA_XMS" ]           && JAVA_XMS="-Xms512m" #START
[ ! "$JAVA_XMX" ]           && JAVA_XMX="-Xmx4096m" #MAX
[ ! "$JAVA_AM_XMS" ]        && JAVA_AM_XMS="-Xms512m" #START
[ ! "$JAVA_AM_XMX" ]        && JAVA_AM_XMX="-Xmx1024m" #MAX

# Hadoop 1 and 2
[ ! "$HADOOP_VERSION" ] && HADOOP_VERSION="hadoop-2.7.3" #"hadoop-1.2.1" #default Hadoop version (use package name)
[ ! "$HADOOP_OPTS" ]    && HADOOP_OPTS="" # Extra hadoop options
[ ! "$YARN_OPTS" ]      && YARN_OPTS="" # Extra hadoop yarn options

# Hive
[ ! "$HIVE_VERSION" ] && HIVE_VERSION="apache-hive-1.2.2-bin" #default Hive version (use package name)
[ ! "$ENGINE" ] && ENGINE="hive" #Available options are: spark_sql and hive
[ ! "$HIVE_FILEFORMAT" ] && HIVE_FILEFORMAT="ORC" # Available options are: EXTFILE, RCFILE, ORC(default), SEQUENCEFILE, PARQUET, AVRO,
[ ! "$HIVE_ENGINE" ] && HIVE_ENGINE="tez" # Available options are: tez (default, hadoop 2 only), mr (MapReduce)
[ ! "$HIVE_ML_FRAMEWORK" ] && HIVE_ML_FRAMEWORK="spark" # Available options are: spark, mahout(default)
[ ! "$BB_SERVER_DERBY" ] && BB_SERVER_DERBY="true" # Available options are: true(Server/Client deployment), false(embeded only)

if [ "$HIVE_ENGINE" == "mr" ]; then #For MapReduce DO NOT do MapJoins, MR uses lots of memory and tends to fail anyways because of high Garbage Collection times.
  HIVE_JOINS="false"
else
  HIVE_JOINS="true"
fi

# Spark
[ ! "$SPARK_VERSION" ] && SPARK_VERSION="spark-1.6.3" #use full folder name

# Spark with Hive support
[ ! "$SPARK_HIVE" ] && SPARK_HIVE="spark_hive-1.6.2" #use full folder name

# Pig
[ ! "$PIG_VERSION" ] && PIG_VERSION="pig-0.15.0"

# Tez
[ ! "$TEZ_VERSION" ] && TEZ_VERSION="0.7.0"

# Mahout
[ ! "$MAHOUT_VERSION" ] && MAHOUT_VERSION="0.12.2"

# Derby
[ ! "$DERBY_VERSION" ]  && DERBY_VERSION="db-derby-10.13.1.1-bin" #Package namef

# HBase
[ ! "$HBASE_VERSION" ] && HBASE_VERSION="1.2.4"
[ ! "$HBASE_MANAGES_ZK" ] && HBASE_MANAGES_ZK=true
[ ! "$HBASE_ROOT_DIR" ] && HBASE_ROOT_DIR=/hbase

# example for bucket cache
#HBASE_CACHE=/hadoop/cache/bucketcache   # this is a file, not a directory
#HBASE_BUCKETCACHE_SIZE=50000       # this is in MB

# YCSB
[ ! "$YCSB_VERSION" ] && YCSB_VERSION="0.11.0"
[ ! "$YCSB_OPERATIONCOUNT" ] && YCSB_OPERATIONCOUNT=$BENCH_DATA_SIZE
[ ! "${YCSB_THREADS}" ] && YCSB_THREADS=10

#BigBench
[ ! "$BB_HDFS_ABSPATH" ]  && BB_HDFS_ABSPATH=""
[ ! "$BB_PARALLEL_STREAMS" ] && BB_PARALLEL_STREAMS="2" #Number of paralel streams for the thoughput test
[ ! "$BB_MODE" ] && BB_MODE="sequential" # Available options are: squential(default), parallel
if [ ! "$BB_SCALE_FACTORS" ] ; then
  if [ "$BENCH_SCALE_FACTOR" == 0 ] ; then
    BB_SCALE_FACTORS=$((BB_SCALE_FACTORS + 1))
  else
    BB_SCALE_FACTORS=$BENCH_SCALE_FACTOR
  fi
fi

#Name of tarball with extra jars for HADOOP_USER_CLASSPATH_FIRST from the public repo
[ ! "$HADOOP_EXTRA_JARS" ] && HADOOP_EXTRA_JARS=""

# Set the max number of maps (and reducers) to 1 per core by default
if [ ! "$MAX_MAPS" ] ; then
  if [ "$vmCores" ] ; then
    MAX_MAPS="$vmCores"
  else
    die "Numbes of cores not defined for cluster, cannot set maps automatically"
  fi
fi

[ ! "$REPLICATION" ]      && REPLICATION=1
[ ! "$BLOCK_SIZE" ]       && BLOCK_SIZE=134217728 #128MB in bytes
[ ! "$IO_FACTOR" ]        && IO_FACTOR=10
[ ! "$IO_FILE" ]          && IO_FILE=65536
[ ! "$COMPRESS_GLOBAL" ]  && COMPRESS_GLOBAL=0
[ ! "$COMPRESS_TYPE" ]    && COMPRESS_TYPE=0

#COMPRESS_GLOBAL=1
#COMPRESS_TYPE=1
#COMPRESS_CODEC_GLOBAL=org.apache.hadoop.io.compress.DefaultCodec
#COMPRESS_CODEC_GLOBAL=com.hadoop.compression.lzo.LzoCodec
#COMPRESS_CODEC_GLOBAL=org.apache.hadoop.io.compress.SnappyCodec

[ ! "$INSTRUMENTATION" ] && INSTRUMENTATION=0 #if to use extrae
[ ! "$BENCH_KEEP_FILES" ] && DELETE_HDFS="1" #if to delete current HDFS files (default)
#[ "$BENCH_LEAVE_SERVICES" ] &&  DELETE_HDFS="" # unset delete HDFS is leaving services

# Hadoop 2 (and Hive)
if [ ! "$OS_RESERVED_MEM_MB" ] ; then
  if (( $(( vmRAM * 1024 )) <= 8192 )) ; then
    OS_RESERVED_MEM_MB="256"
  elif (( $(( vmRAM * 1024 )) <= 16384 )) ; then
    OS_RESERVED_MEM_MB="512"
  elif (( $(( vmRAM * 1024 )) >= 61440 )) ; then
    OS_RESERVED_MEM_MB="10240"
  fi
fi

# Set the max ammount of memory for the node manager from cluster specs
[ ! "$PHYS_MEM" ] && PHYS_MEM="$(printf %.$2f $(echo "($vmRAM*1024)-$OS_RESERVED_MEM_MB" | bc))"
[ ! "$AM_MB" ]  && AM_MB=768

[ ! "$MAPS_MB" ] && [ "$JAVA_XMX" ] && MAPS_MB="${JAVA_XMX//[!0-9]}"
[ ! "$REDUCES_MB" ] && [ "$JAVA_XMX" ] && REDUCES_MB="${JAVA_XMX//[!0-9]}"

[ ! "$NUM_CORES" ] && NUM_CORES="$vmCores"

[ ! "$CONTAINER_MIN_MB" ] && CONTAINER_MIN_MB=512
[ ! "$CONTAINER_MAX_MB" ] && CONTAINER_MAX_MB="$(printf %.$2f $(echo "($MAPS_MB) + (384)" | bc))" #To be able to allocate Spark executors with executor.mem=MAPS_MB
YARN_MAX_MEM="$PHYS_MEM"

# Spark specific
[ ! "$NUM_EXECUTOR_NODE" ] && NUM_EXECUTOR_NODE="$vmCores" # 1 executor per node as default
[ ! "$EXECUTOR_CORES" ] && EXECUTOR_CORES="1" # with all the cores
[ ! "$EXECUTOR_MEM" ] && EXECUTOR_MEM="$MAPS_MB" # in MB

# Config for very small installs i.e. vagrant (local) devel runs
# check if we are below YARN memory minimums
if (( "$PHYS_MEM" <= 2048 )) ; then
    CONTAINER_MIN_MB="512" #set to 512 on VMs with less than 2GB usable mem
    MAPS_MB=512
    REDUCES_MB=512
    PHYS_MEM="$(printf %.$2f $(echo "($vmRAM*1024)-128" | bc))"
    CONTAINER_MAX_MB="$(printf %.$2f $(echo "($MAPS_MB) + (384)" | bc))"
    CONTAINER_MIN_MB="512" #set to 512 on VMs with less than 2GB usable mem
    NUM_EXECUTOR_NODE=1
    EXECUTOR_MEM="$MAPS_MB" #Minimum requirement: 412MB
    AM_MB=256
    JAVA_XMX="-Xmx1536m" #MAX
    HIVE_JOINS="false" #Never do MapJoins if not enough memory is available
    BB_MINIMUM_DATA=1
    YARN_MAX_MEM=2536
    BB_SCALE_FACTORS="min"
fi

# Bench specific configs
[ ! "$TPCH_SCALE_FACTOR" ] &&  TPCH_SCALE_FACTOR=1 #1GB min size

# File format
[ ! "$BENCH_FILE_FORMAT" ] && BENCH_FILE_FORMAT="orc"

# Default cluster capabilities
[ ! "$CLUSTER_DISKS" ] &&   CLUSTER_DISKS="HDD" #separate list with spaces
[ ! "$CLUSTER_NETS" ] &&    CLUSTER_NETS="ETH" #separate list with spaces
[ ! "$BENCH_MAX_DISKS" ] && BENCH_MAX_DISKS="8"

# To populate if needed with config folders to rsync
BENCH_CONFIG_FOLDERS=""

# SATA drives (HDDs)
BENCH_DISKS["HDD"]="$BENCH_LOCAL_DIR"

# Create automatically disk paths
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["HD$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# SSDs
BENCH_DISKS["SSD"]="/scratch/ssd/1"

for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["SS$disk_number_tmp"]="/scratch/ssd/$disk_number_tmp"
done

# Remotes
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RR$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Remotes with temp in local
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RL$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Sata with tmp in SSD
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["HS$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# Remotes with tmp in SSD
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["RS$disk_number_tmp"]="/scratch/attached/$disk_number_tmp"
done

# SATA drives (HDDs)
BENCH_DISKS["NFS"]="/scratch/nfs/1"

# Create automatically disk paths
for disk_number_tmp in $(seq  1 $BENCH_MAX_DISKS) ; do
  BENCH_DISKS["NFS$disk_number_tmp"]="/scratch/nfs/$disk_number_tmp"
done
